

Aqui está o texto formatado de forma mais organizada:

---

# Bootcamp BairesDev

## Bootcamp BairesDev - Machine Learning Practitioner - Desafios

---

### 🚀 **Descrição do Projeto - Desafio 1**
Este projeto implementa uma solução de aprendizado profundo para classificar dígitos manuscritos usando o conjunto de dados MNIST. Ele combina a simplicidade do MNIST com a sofisticação de redes neurais convolucionais modernas através de **transfer learning** utilizando a **MobileNetV2**. O pipeline do projeto pode ser descrito em etapas principais:

#### 📂 **Carregamento e Pré-processamento dos Dados**
- 🔹 O conjunto de dados MNIST é carregado, contendo imagens de dígitos manuscritos de tamanho 28x28 pixels.  
- 🔹 As imagens são normalizadas para valores entre 0 e 1 e convertidas para um formato compatível com redes convolucionais (28x28x1).  
- 🔹 As labels dos dígitos são transformadas em formato categórico para classificação de 10 classes (dígitos de 0 a 9).

#### 🧠 **Transfer Learning com MobileNetV2**
- ⚙️ A **MobileNetV2**, uma arquitetura moderna pré-treinada na ImageNet, é utilizada como base.  
- 🛠️ As camadas da MobileNetV2 são congeladas para reutilizar seus recursos extraídos sem treinamento adicional.  
- 🎨 As imagens MNIST, originalmente monocromáticas (1 canal), são redimensionadas para 224x224 pixels e convertidas para 3 canais (RGB) para compatibilidade com a MobileNetV2.

#### 🏗️ **Construção do Modelo**
- 🔧 O modelo consiste em camadas adicionais para ajustar as entradas do MNIST à MobileNetV2 e processar sua saída.  
- 🔗 Inclui uma camada de **pooling global** e uma camada **densa** com ativação **softmax** para produzir as probabilidades das 10 classes.

#### 🏋️ **Treinamento e Avaliação**
- 📊 O modelo é treinado por 10 épocas usando o otimizador **Adam** e a função de perda de **entropia cruzada categórica**.  
- ✅ O desempenho é avaliado no conjunto de teste, com a métrica de **acurácia** como principal indicador.

#### 📈 **Visualização**
- 🖼️ A evolução da acurácia no conjunto de treinamento e validação é plotada para analisar o desempenho ao longo das épocas.

#### 🎯 **Objetivo do Projeto**
Explorar a aplicação de **transfer learning** em tarefas simples como a classificação de dígitos manuscritos, utilizando uma arquitetura moderna e eficiente como a **MobileNetV2** para:
- ⚡ Acelerar o desenvolvimento.  
- 🎯 Melhorar a precisão do modelo.

#### 🏆 **Resultados Esperados**
- 🎉 Uma **alta acurácia** na classificação dos dígitos do MNIST.  
- 💡 Demonstração da eficácia de **transfer learning** mesmo em problemas com dados diferentes do domínio da ImageNet.  
Este projeto é ideal para estudantes ou profissionais que desejam aprender sobre **transfer learning** e combinar redes modernas com datasets clássicos.

---

## 🖼️ **Desafio de Processamento de Imagens - Desafio 2**

### 📋 **Descrição do Desafio**
Seguindo o exemplo do algoritmo de binarização apresentado em nossa última aula, implemente um programa em **Python** 🐍 que realize as seguintes transformações em uma imagem colorida:
- Converter a imagem para **níveis de cinza** (valores de 0 a 255).
- Converter a imagem para **binária** (preto e branco, com valores de 0 e 255).

### 🎯 **Objetivo**
A partir da imagem de entrada (colorida), obtenha duas saídas:
1. A imagem em **níveis de cinza**.
2. A imagem **binarizada**.

### 🚀 **Boa sorte no desafio e mãos à obra!**

---

## 📊 **Desafio 3: Cálculo de Métricas de Avaliação de Aprendizado**

### 📝 **Descrição do Desafio**
Neste projeto, você irá calcular as principais métricas utilizadas para avaliar modelos de classificação de dados. Neste projeto, você irá calcular as principais métricas utilizadas para avaliar modelos de classificação de dados, com o objetivo de aplicar essas métricas a um modelo treinado no dataset Iris 🌸. Este é um dataset amplamente utilizado em aprendizado de máquina e contém 150 amostras de flores de íris, distribuídas em 3 classes, com 4 características cada: comprimento e largura da sépala e da pétala. As métricas incluem:

- Acurácia
- Sensibilidade (Recall)
- Especificidade
- Precisão
- F-score

Para implementar as funções de cálculo, utilize os métodos e fórmulas correspondentes apresentadas na Tabela 1.

---

#### 🟢 **Matriz de Confusão**
Os valores de VP (Verdadeiros Positivos), VN (Verdadeiros Negativos), FP (Falsos Positivos) e FN (Falsos Negativos) serão necessários para os cálculos. Você pode escolher arbitrariamente uma matriz de confusão, já que o objetivo principal é compreender o funcionamento das métricas.

---

#### 📋 **Tabela 1: Fórmulas das Métricas de Avaliação**

| Métrica           | Fórmula | Descrição |
|-------------------|---------|-----------|
| Acurácia          | ((VP + VN) / (VP + VN + FP + FN)) | Proporção de previsões corretas |
| Precisão (P)      | (VP / (VP + FP)) | Porcentagem de positivos corretos |
| Sensibilidade (S) | (VP / (VP + FN)) | Habilidade de identificar positivos |
| Especificidade    | (VN / (VN + FP)) | Habilidade de identificar negativos |
| F-score           | (2 * (P * S) / (P + S)) | Média harmônica de Precisão e Recall |

Legenda:
- VP: Verdadeiros Positivos
- VN: Verdadeiros Negativos
- FP: Falsos Positivos
- FN: Falsos Negativos

---

⚡ **Dica**: Entender e implementar as métricas será essencial para avaliar a eficácia de modelos de classificação e tomar decisões com base nos resultados obtidos.

🚀 **Mãos à obra!**

--- 

Isso ajuda a organizar melhor as informações.
