{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI/SBdisZmo5Q6qdVt88B+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunokobi/Bootcamp_BairesDev/blob/main/Sistema_recomenda%C3%A7%C3%A3o_imagens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸ¯ Projeto: Sistema de RecomendaÃ§Ã£o por Similaridade de Imagens no Colab ğŸ–¼ï¸ğŸ¤\n",
        "\n",
        "##ğŸ” Objetivo\n",
        "\n",
        "Criar um sistema de recomendaÃ§Ã£o simples e eficiente que funcione diretamente no Google Colab. O sistema recomendarÃ¡ imagens de produtos similares com base na aparÃªncia visual, considerando caracterÃ­sticas como formato, cor e textura. Ideal para e-commerce e outros cenÃ¡rios! ğŸ›’ğŸ‘•ğŸ‘"
      ],
      "metadata": {
        "id": "7Tl6jgeQOdYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ Resumo do Projeto\n",
        "\n",
        "- **Dataset:** Fashion MNIST ğŸ¨  \n",
        "- **Modelo:** Utilizamos MobileNetV2 prÃ©-treinado para extrair caracterÃ­sticas visuais ğŸ’¡.  \n",
        "- **Similaridade:** Calculamos similaridades usando Cosine Similarity ğŸ”—.  \n",
        "- **VisualizaÃ§Ã£o:** RecomendaÃ§Ã£o de itens visualizada diretamente no Colab com Matplotlib ğŸ–¼ï¸.  \n",
        "- **Testes:** Permite testar com imagens customizadas ğŸ“¥.  \n",
        "\n",
        "#### ğŸ› ï¸ Bibliotecas Usadas\n",
        "- TensorFlow  \n",
        "- Matplotlib  \n",
        "- NumPy  \n",
        "\n",
        "#### âš¡ Vantagens\n",
        "- Projeto rÃ¡pido e leve.  \n",
        "- Funciona diretamente no Colab!  \n",
        "\n",
        "Se precisar de mais detalhes ou ajuda para ajustar, Ã© sÃ³ avisar! ğŸš€ğŸ˜Š"
      ],
      "metadata": {
        "id": "Y97unm7aTjJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ› ï¸ Passo a Passo para ConstruÃ§Ã£o do Projeto\n",
        "###1ï¸âƒ£ Configurando o Ambiente\n",
        "\n",
        "ğŸ“Œ Primeiro, instalamos as bibliotecas essenciais no Colab para manter o projeto leve e rÃ¡pido:"
      ],
      "metadata": {
        "id": "dnANpw8FPEKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmg8SwIzOUN6"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow matplotlib numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2ï¸âƒ£ Selecionando o Dataset\n",
        "\n",
        "ğŸ’¾ Para simplificar, utilizaremos o dataset Fashion MNIST, embutido no TensorFlow. Ele contÃ©m 10 categorias de produtos (como camisetas, sapatos, bolsas) em imagens de baixa resoluÃ§Ã£o.\n",
        "\n",
        "ğŸ·ï¸ Categorias disponÃ­veis:\n",
        "\n",
        "0: T-shirt/top ğŸ‘•\n",
        "\n",
        "1: Trouser ğŸ‘–\n",
        "\n",
        "2: Pullover ğŸ§¥\n",
        "\n",
        "3: Dress ğŸ‘—\n",
        "\n",
        "4: Coat ğŸ§¥\n",
        "\n",
        "5: Sandal ğŸ©´\n",
        "\n",
        "6: Shirt ğŸ‘”\n",
        "\n",
        "7: Sneaker ğŸ‘Ÿ\n",
        "\n",
        "8: Bag ğŸ‘œ\n",
        "\n",
        "9: Ankle boot ğŸ‘¢"
      ],
      "metadata": {
        "id": "6J7bhGtcQI1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "1Ig4NSc4Qi1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3ï¸âƒ£ Criando o Modelo de Deep Learning\n",
        "\n",
        "ğŸ’¡ Usaremos o modelo prÃ©-treinado MobileNetV2 para extrair embeddings (representaÃ§Ãµes matemÃ¡ticas das imagens) e identificar similaridades.\n",
        "\n",
        "ğŸ“‹ Passos:\n",
        "\n",
        "Adicione camadas extras para simplificar a saÃ­da.\n",
        "Use o modelo como \"feature extractor\" (extrator de caracterÃ­sticas)."
      ],
      "metadata": {
        "id": "FMnlFqRiQnWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Carregando o MobileNetV2\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Adicionando camada de pooling global\n",
        "model = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n"
      ],
      "metadata": {
        "id": "v8oR8Vz2Q1c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4ï¸âƒ£ Processando as Imagens ğŸ–Œï¸\n",
        "\n",
        "ğŸ¨ Precisamos redimensionar e normalizar as imagens para que sejam compatÃ­veis com o modelo:"
      ],
      "metadata": {
        "id": "auWDEu77RMtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.image import resize\n",
        "\n",
        "def preprocess_images(images):\n",
        "    images = np.array([resize(img, (128, 128)).numpy() for img in images])  # Redimensiona para 128x128\n",
        "    return np.repeat(images[..., np.newaxis], 3, axis=-1) / 255.0  # Normaliza e converte para 3 canais\n",
        "\n",
        "x_train_processed = preprocess_images(x_train)\n",
        "x_test_processed = preprocess_images(x_test)"
      ],
      "metadata": {
        "id": "SZ3aS7U4Rcuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5ï¸âƒ£ Gerando Embeddings ğŸ”¢\n",
        "\n",
        "ğŸ“Œ Usaremos o modelo para transformar as imagens em embeddings, que sÃ£o representaÃ§Ãµes matemÃ¡ticas no espaÃ§o latente."
      ],
      "metadata": {
        "id": "s3O0nf3-RmxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings = model.predict(x_train_processed)\n",
        "test_embeddings = model.predict(x_test_processed)"
      ],
      "metadata": {
        "id": "481RLBYMRxXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6ï¸âƒ£ Calculando Similaridade ğŸ§®\n",
        "\n",
        "ğŸ” Para recomendar imagens, utilizamos a distÃ¢ncia de similaridade coseno entre os embeddings."
      ],
      "metadata": {
        "id": "5WqEKUZCR1rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_similar_images(query_embedding, embeddings, k=5):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)  # Calcula similaridade\n",
        "    indices = np.argsort(similarities[0])[::-1][:k]  # Ordena por similaridade\n",
        "    return indices"
      ],
      "metadata": {
        "id": "yA0IxFyoR_oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7ï¸âƒ£ Visualizando RecomendaÃ§Ãµes ğŸ–¼ï¸âœ¨\n",
        "\n",
        "ğŸ“¸ Mostramos as imagens similares ao usuÃ¡rio diretamente no Colab usando Matplotlib."
      ],
      "metadata": {
        "id": "TD-6Mb6XSDiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images(indices, images):\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i, idx in enumerate(indices):\n",
        "        plt.subplot(1, len(indices), i + 1)\n",
        "        plt.imshow(images[idx].squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Testando com uma imagem de exemplo\n",
        "query_index = 0  # Ãndice da imagem de consulta\n",
        "similar_indices = get_similar_images(train_embeddings[query_index], train_embeddings)\n",
        "plot_images(similar_indices, x_train)"
      ],
      "metadata": {
        "id": "oF7xxX73SOH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8ï¸âƒ£ Teste com Imagens Customizadas ğŸ“¥\n",
        "\n",
        "ğŸ”„ Permita que o usuÃ¡rio faÃ§a upload de uma imagem para testar recomendaÃ§Ãµes:"
      ],
      "metadata": {
        "id": "ObWl6rL6SR9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    img = image.load_img(filename, target_size=(128, 128))\n",
        "    img_array = np.expand_dims(np.array(img) / 255.0, axis=0)\n",
        "    query_embedding = model.predict(img_array)\n",
        "    similar_indices = get_similar_images(query_embedding[0], train_embeddings)\n",
        "    plot_images(similar_indices, x_train)"
      ],
      "metadata": {
        "id": "9f0cJL7kSZL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aUfCRr7OSfvZ"
      }
    }
  ]
}