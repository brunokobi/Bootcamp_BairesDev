{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGaOpBbDTJPXHKzqm49v5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunokobi/Bootcamp_BairesDev/blob/main/AssistenteVirtual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Claro! Aqui est√° a descri√ß√£o do sistema com emojis para torn√°-lo mais visual e divertido:\n",
        "\n",
        "### Descri√ß√£o da Implementa√ß√£o do Sistema de Assist√™ncia Virtual ü§ñüéôÔ∏è\n",
        "\n",
        "O objetivo deste projeto √© criar um sistema de assist√™ncia virtual utilizando Processamento de Linguagem Natural (PLN) com funcionalidades de convers√£o de texto em √°udio (Text-to-Speech) e de fala para texto (Speech-to-Text), al√©m de permitir a execu√ß√£o de comandos de voz para a√ß√µes automatizadas, como pesquisa no Wikipedia, acesso ao YouTube e busca de locais (como farm√°cias pr√≥ximas).\n",
        "\n",
        "A implementa√ß√£o est√° dividida em m√≥dulos principais, que s√£o descritos a seguir:\n",
        "\n",
        "### 1. **M√≥dulo de Convers√£o de Texto para Fala (Text-to-Speech) üó£Ô∏èüéß**\n",
        "\n",
        "A convers√£o de texto para fala √© realizada utilizando a biblioteca `pyttsx3`. Esta biblioteca permite transformar uma string de texto em uma sa√≠da de √°udio. O processo √© simples e envolve o uso do motor de s√≠ntese de voz para falar o texto recebido como argumento.\n",
        "\n",
        "- **Fun√ß√£o**: `text_to_speech(text)`\n",
        "  - **Entrada**: Recebe uma string de texto.\n",
        "  - **Sa√≠da**: Converte o texto em √°udio e o reproduz.\n",
        "  - **Objetivo**: Fornecer respostas aud√≠veis ao usu√°rio com base nas a√ß√µes realizadas pelo assistente.\n",
        "\n",
        "### 2. **M√≥dulo de Convers√£o de Fala para Texto (Speech-to-Text) üéôÔ∏è‚û°Ô∏èüìù**\n",
        "\n",
        "A convers√£o de fala para texto √© feita com a ajuda da biblioteca `SpeechRecognition`. Este m√≥dulo captura o √°udio do microfone, processa a fala e a converte em texto utilizando o servi√ßo de reconhecimento de fala do Google.\n",
        "\n",
        "- **Fun√ß√£o**: `speech_to_text()`\n",
        "  - **Entrada**: Nenhuma (captura √°udio do microfone).\n",
        "  - **Sa√≠da**: Retorna a string de texto reconhecida a partir da fala.\n",
        "  - **Objetivo**: Permitir ao usu√°rio interagir com o assistente virtual por meio de comandos de voz.\n",
        "\n",
        "### 3. **Fun√ß√µes Automatizadas Baseadas em Comandos de Voz üîäüì±**\n",
        "\n",
        "O sistema √© projetado para executar fun√ß√µes espec√≠ficas quando certos comandos de voz s√£o reconhecidos. Aqui est√£o algumas das funcionalidades implementadas:\n",
        "\n",
        "- **Pesquisar no Wikipedia**: Quando o usu√°rio disser \"pesquisar no Wikipedia\", o sistema buscar√° o conte√∫do relacionado ao comando fornecido e ler√° um resumo.\n",
        "  - **Fun√ß√£o**: `open_wikipedia(query)`\n",
        "    - **Entrada**: Um comando de pesquisa extra√≠do da fala.\n",
        "    - **Sa√≠da**: Realiza uma pesquisa no Wikipedia e retorna um resumo.\n",
        "    - **Objetivo**: Fornecer informa√ß√µes relevantes ao usu√°rio sobre um t√≥pico.\n",
        "\n",
        "- **Abrir o YouTube**: O comando \"abrir o YouTube\" ir√° abrir o navegador e direcion√°-lo para o site do YouTube.\n",
        "  - **Fun√ß√£o**: `open_youtube()`\n",
        "    - **Entrada**: Nenhuma.\n",
        "    - **Sa√≠da**: O navegador √© aberto com o YouTube.\n",
        "    - **Objetivo**: Facilitar o acesso a v√≠deos diretamente a partir do assistente.\n",
        "\n",
        "- **Localizar a Farm√°cia Mais Pr√≥xima**: Um comando de voz como \"farm√°cia\" pode ser usado para acionar uma fun√ß√£o que busque a farm√°cia mais pr√≥xima.\n",
        "  - **Fun√ß√£o**: `find_nearest_pharmacy()`\n",
        "    - **Entrada**: Nenhuma (simula uma busca pela farm√°cia).\n",
        "    - **Sa√≠da**: Fornece informa√ß√µes sobre a farm√°cia mais pr√≥xima (aqui, apenas uma simula√ß√£o).\n",
        "    - **Objetivo**: Implementar a busca de locais utilizando APIs de geolocaliza√ß√£o (para ser expandido no futuro).\n",
        "\n",
        "### 4. **Loop de Espera para Comandos de Voz üîÑüé§**\n",
        "\n",
        "O assistente virtual est√° sempre ouvindo para novos comandos de voz. O loop principal (`assistant()`) vai capturar comandos cont√≠nuos e executar as fun√ß√µes correspondentes, como pesquisar no Wikipedia, abrir o YouTube ou localizar farm√°cias. O loop √© encerrado quando o comando \"sair\" √© reconhecido.\n",
        "\n",
        "- **Fun√ß√£o**: `assistant()`\n",
        "  - **Entrada**: Nenhuma (inicia o ciclo de escuta).\n",
        "  - **Sa√≠da**: Processa e executa os comandos de voz reconhecidos.\n",
        "  - **Objetivo**: Manter o assistente em execu√ß√£o, esperando e respondendo a comandos de voz do usu√°rio.\n",
        "\n",
        "### Expans√£o e Personaliza√ß√£o üöÄ\n",
        "\n",
        "Este sistema pode ser expandido de v√°rias maneiras:\n",
        "\n",
        "- **Reconhecimento de comandos mais complexos**: √â poss√≠vel adicionar mais comandos e fun√ß√µes espec√≠ficas, como abrir aplicativos ou realizar pesquisas na web.\n",
        "- **Integra√ß√£o com APIs de geolocaliza√ß√£o**: Para aprimorar a funcionalidade de encontrar farm√°cias ou outros locais pr√≥ximos, podemos integrar o sistema com APIs como o Google Maps ou outras fontes de dados geogr√°ficos.\n",
        "- **Aprimoramento da precis√£o do reconhecimento de fala**: Embora o servi√ßo de reconhecimento de fala do Google seja eficaz, ele pode ser configurado para funcionar com diferentes idiomas, ou at√© mesmo utilizar outros servi√ßos de reconhecimento de fala para melhorar a precis√£o.\n",
        "\n",
        "### Conclus√£o üéØ\n",
        "\n",
        "Este sistema b√°sico de assistente virtual usa PLN e reconhecimento de fala para realizar a√ß√µes simples e fornecer uma intera√ß√£o mais natural com o usu√°rio. Com a adi√ß√£o de mais funcionalidades e personaliza√ß√µes, o assistente pode ser expandido para se tornar mais √∫til em diferentes contextos, como tarefas di√°rias, consultas √† web ou at√© mesmo em dom√≠nios mais espec√≠ficos."
      ],
      "metadata": {
        "id": "aK8HpNJAqLT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Colab: Sistema de Assist√™ncia Virtual com PLN\n",
        "\n",
        "1 - Instala√ß√£o de Depend√™ncias"
      ],
      "metadata": {
        "id": "JiaykYsCqh6D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwdHORmSmaDp",
        "outputId": "0966a291-07f3-48ab-b544-bb39f0e183dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyttsx3\n",
            "  Using cached pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting SpeechRecognition\n",
            "  Using cached SpeechRecognition-3.13.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wikipedia\n",
            "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Using cached pyttsx3-2.98-py3-none-any.whl (34 kB)\n",
            "Using cached SpeechRecognition-3.13.0-py3-none-any.whl (32.8 MB)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pyttsx3 SpeechRecognition pyaudio wikipedia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - Importa√ß√£o de Bibliotecas:"
      ],
      "metadata": {
        "id": "o6LMaBJPuXGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "import speech_recognition as sr\n",
        "import wikipedia\n",
        "import webbrowser\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "myJ9D_lXuh1R",
        "outputId": "2e87a5f5-430c-45f0-ca95-4906c5c8f549"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyttsx3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-afd6d08bd4e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyttsx3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebbrowser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyttsx3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - Fun√ß√£o de Text-to-Speech (Texto para Fala):"
      ],
      "metadata": {
        "id": "_W3RXRgku0fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o de texto para fala\n",
        "def text_to_speech(text):\n",
        "    engine = pyttsx3.init()\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n"
      ],
      "metadata": {
        "id": "RJjtIDI2u653"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 - Fun√ß√£o de Speech-to-Text (Fala para Texto):"
      ],
      "metadata": {
        "id": "NZaC_ucGu-SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o de fala para texto\n",
        "def speech_to_text():\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Aguardando comando de voz...\")\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    try:\n",
        "        command = recognizer.recognize_google(audio)\n",
        "        print(f\"Voc√™ disse: {command}\")\n",
        "        return command.lower()\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"N√£o consegui entender o que voc√™ disse.\")\n",
        "        return None\n",
        "    except sr.RequestError:\n",
        "        print(\"N√£o foi poss√≠vel se conectar ao servi√ßo de reconhecimento de fala.\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "mDxZGTNmvGuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 - Fun√ß√µes de A√ß√£o Baseadas em Comandos de Voz:"
      ],
      "metadata": {
        "id": "lgFEMqrmvJQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√µes automatizadas acionadas por voz\n",
        "def open_wikipedia(query):\n",
        "    try:\n",
        "        result = wikipedia.summary(query, sentences=1)\n",
        "        print(result)\n",
        "        text_to_speech(result)\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        print(\"Ambiguidades encontradas. Por favor, refine sua busca.\")\n",
        "        text_to_speech(\"Ambiguidades encontradas. Por favor, refine sua busca.\")\n",
        "    except wikipedia.exceptions.HTTPTimeoutError:\n",
        "        print(\"Erro de conex√£o com o Wikipedia.\")\n",
        "        text_to_speech(\"Erro de conex√£o com o Wikipedia.\")\n",
        "\n",
        "def open_youtube():\n",
        "    print(\"Abrindo o YouTube...\")\n",
        "    webbrowser.open(\"https://www.youtube.com\")\n",
        "    text_to_speech(\"Abrindo o YouTube.\")\n",
        "\n",
        "def find_nearest_pharmacy():\n",
        "    # Exemplo simplificado para localiza√ß√£o (substituir por c√≥digo real de geolocaliza√ß√£o)\n",
        "    print(\"Encontrando a farm√°cia mais pr√≥xima...\")\n",
        "    text_to_speech(\"Aqui est√° a farm√°cia mais pr√≥xima.\")\n",
        "    # Coloque aqui o c√≥digo real de localiza√ß√£o ou API de geolocaliza√ß√£o\n"
      ],
      "metadata": {
        "id": "dHXAIspTvOuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 - Loop para Esperar Comandos de Voz e Executar Fun√ß√µes:"
      ],
      "metadata": {
        "id": "88oNmX11vT8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assistant():\n",
        "    text_to_speech(\"Assistente virtual ativado. Como posso te ajudar?\")\n",
        "    while True:\n",
        "        command = speech_to_text()\n",
        "        if command:\n",
        "            if 'wikipedia' in command:\n",
        "                query = command.replace('pesquisar no wikipedia', '')\n",
        "                open_wikipedia(query)\n",
        "            elif 'youtube' in command:\n",
        "                open_youtube()\n",
        "            elif 'farm√°cia' in command:\n",
        "                find_nearest_pharmacy()\n",
        "            elif 'sair' in command:\n",
        "                text_to_speech(\"Assistente desativado.\")\n",
        "                break\n",
        "            else:\n",
        "                text_to_speech(\"Desculpe, n√£o entendi o comando.\")\n"
      ],
      "metadata": {
        "id": "2pXFJvAVvaZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 - Executando o Sistema de Assistente Virtual:"
      ],
      "metadata": {
        "id": "3Kdq4Uc1vd4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant()\n"
      ],
      "metadata": {
        "id": "EmDPzfuUvkcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9_kqB1Ryvnxa"
      }
    }
  ]
}